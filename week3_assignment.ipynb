{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Assignment: week 3",
   "id": "c7e35a831a135f1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T21:03:46.495316Z",
     "start_time": "2025-04-09T21:03:46.491796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras.src.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import layers, Sequential, regularizers\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.optimizers import Adam"
   ],
   "id": "7f1f0b312e98df5f",
   "outputs": [],
   "execution_count": 198
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Data preparation\n",
    "\n",
    "In this section, we prepare the CIFAR-10 dataset for training, validation, and testing. The process includes loading the data, splitting it into subsets, preprocessing the images, and one-hot encoding the target labels. Since we're using the pretrained VGG16 model for feature extraction, it’s important to preprocess the images to match the format the model was trained on. Without the preprocess_input function, the model performs poorly due to mismatched input data."
   ],
   "id": "6ed5e726862ea8ac"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T21:03:47.883104Z",
     "start_time": "2025-04-09T21:03:46.498316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data and split it between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Split training data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# One hot encode targets\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "y_val = to_categorical(y_val, 10)\n",
    "\n",
    "# Apply preprocessing for VGG16\n",
    "X_train = preprocess_input(X_train)\n",
    "X_val = preprocess_input(X_val)\n",
    "X_test = preprocess_input(X_test)\n",
    "\n",
    "# Ensure correct shapes before continuing\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ],
   "id": "842e3b4d9caec2fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 32, 32, 3) (40000, 10)\n",
      "(10000, 32, 32, 3) (10000, 10)\n",
      "(10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "execution_count": 199
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Loading the convolutional base (VGG16) and freezing the trainable layers.\n",
    "\n",
    "We load the VGG16 model with pretrained weights from ImageNet, excluding classifier layers. The convolutional base is then frozen to preserve the learned features and prevent them from being updated during training, allowing us to use them for feature extraction."
   ],
   "id": "b20d55fecd62a8de"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T21:03:48.085877Z",
     "start_time": "2025-04-09T21:03:47.900909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load model without classifier layers\n",
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze the layers of the convolutional base\n",
    "conv_base.trainable = False\n",
    "\n",
    "conv_base.summary()"
   ],
   "id": "7c163785e22ae375",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"vgg16\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"vgg16\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_40 (\u001B[38;5;33mInputLayer\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m3\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │         \u001B[38;5;34m1,792\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │        \u001B[38;5;34m36,928\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (\u001B[38;5;33mMaxPooling2D\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │        \u001B[38;5;34m73,856\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │       \u001B[38;5;34m147,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (\u001B[38;5;33mMaxPooling2D\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │       \u001B[38;5;34m295,168\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │       \u001B[38;5;34m590,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m8\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │       \u001B[38;5;34m590,080\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (\u001B[38;5;33mMaxPooling2D\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m256\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │     \u001B[38;5;34m1,180,160\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │     \u001B[38;5;34m2,359,808\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m4\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │     \u001B[38;5;34m2,359,808\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (\u001B[38;5;33mMaxPooling2D\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │     \u001B[38;5;34m2,359,808\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │     \u001B[38;5;34m2,359,808\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (\u001B[38;5;33mConv2D\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m2\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │     \u001B[38;5;34m2,359,808\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (\u001B[38;5;33mMaxPooling2D\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block1_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block2_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block3_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block4_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_conv3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ block5_pool (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m14,714,688\u001B[0m (56.13 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m14,714,688\u001B[0m (56.13 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,714,688</span> (56.13 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 200
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Extracting features\n",
    "\n",
    "In this step, we use the pretrained VGG16 convolutional base to extract features from the images. The output feature maps are then flattened into 1D vectors, making them suitable for input into a fully connected classifier."
   ],
   "id": "459af660f27fbe8b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T21:05:00.181011Z",
     "start_time": "2025-04-09T21:03:48.103215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract features from images using the pre-trained convolutional base\n",
    "X_train = conv_base.predict(X_train)\n",
    "X_val = conv_base.predict(X_val)\n",
    "X_test = conv_base.predict(X_test)\n",
    "\n",
    "# flatten\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ],
   "id": "e4152b8923c3341d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m46s\u001B[0m 37ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m12s\u001B[0m 39ms/step\n",
      "\u001B[1m313/313\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m13s\u001B[0m 42ms/step\n",
      "(40000, 512) (10000, 512) (10000, 512)\n"
     ]
    }
   ],
   "execution_count": 201
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Building and compiling the classifier\n",
    "\n",
    "I experimented with different model architectures and depths to improve classification performance. The final model ended up with more neurons than initially expected. Although the performance improvement was marginal, I found that deeper layers enhanced the model's ability to generalize on unseen data."
   ],
   "id": "f47ea5a5577ee0d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T21:13:46.690409Z",
     "start_time": "2025-04-09T21:13:46.680311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FCN_TOP = Sequential([\n",
    "    layers.Dense(516, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.4),\n",
    "    layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "FCN_TOP.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "id": "6bf4fbe33190fb8d",
   "outputs": [],
   "execution_count": 228
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Callbacks\n",
    "\n",
    "Callbacks are used to prevent overfitting and optimize the training process by adjusting the learning rate or stopping early if the model's performance plateaus."
   ],
   "id": "577f9c1f640e7103"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T21:13:48.417687Z",
     "start_time": "2025-04-09T21:13:48.414389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ],
   "id": "85df2f38a93052c4",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Training the model",
   "id": "1b5921a049ae9268"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T21:16:24.021311Z",
     "start_time": "2025-04-09T21:13:49.870052Z"
    }
   },
   "cell_type": "code",
   "source": "history = FCN_TOP.fit(X_train, y_train, batch_size=32, validation_data=(X_val, y_val), epochs=100, callbacks=[lr_scheduler, early_stop])",
   "id": "f3ccacb004a65101",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 2ms/step - accuracy: 0.3968 - loss: 9.4107 - val_accuracy: 0.5854 - val_loss: 2.8441 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5753 - loss: 2.4418 - val_accuracy: 0.6156 - val_loss: 1.6375 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5924 - loss: 1.6850 - val_accuracy: 0.6198 - val_loss: 1.5641 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5970 - loss: 1.6054 - val_accuracy: 0.6227 - val_loss: 1.4980 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5984 - loss: 1.5736 - val_accuracy: 0.6276 - val_loss: 1.4552 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5914 - loss: 1.5573 - val_accuracy: 0.6259 - val_loss: 1.4303 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5978 - loss: 1.5195 - val_accuracy: 0.6310 - val_loss: 1.4016 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6023 - loss: 1.5013 - val_accuracy: 0.6135 - val_loss: 1.4186 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5976 - loss: 1.4818 - val_accuracy: 0.6268 - val_loss: 1.3901 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6000 - loss: 1.4715 - val_accuracy: 0.6256 - val_loss: 1.3728 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6024 - loss: 1.4671 - val_accuracy: 0.6184 - val_loss: 1.3787 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5972 - loss: 1.4740 - val_accuracy: 0.6297 - val_loss: 1.3349 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6014 - loss: 1.4418 - val_accuracy: 0.6322 - val_loss: 1.3465 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6033 - loss: 1.4459 - val_accuracy: 0.6292 - val_loss: 1.3653 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5996 - loss: 1.4524 - val_accuracy: 0.6244 - val_loss: 1.3640 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5976 - loss: 1.4494 - val_accuracy: 0.6213 - val_loss: 1.3707 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6030 - loss: 1.4361 - val_accuracy: 0.6393 - val_loss: 1.3141 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5969 - loss: 1.4396 - val_accuracy: 0.6306 - val_loss: 1.3264 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6005 - loss: 1.4349 - val_accuracy: 0.6357 - val_loss: 1.3096 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6041 - loss: 1.4309 - val_accuracy: 0.6273 - val_loss: 1.3292 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6069 - loss: 1.4130 - val_accuracy: 0.6251 - val_loss: 1.3442 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5990 - loss: 1.4329 - val_accuracy: 0.6387 - val_loss: 1.3083 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6044 - loss: 1.4154 - val_accuracy: 0.6273 - val_loss: 1.3310 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6105 - loss: 1.4097 - val_accuracy: 0.6414 - val_loss: 1.3177 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6005 - loss: 1.4215 - val_accuracy: 0.6392 - val_loss: 1.2848 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6004 - loss: 1.4175 - val_accuracy: 0.6430 - val_loss: 1.2969 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6030 - loss: 1.4126 - val_accuracy: 0.6434 - val_loss: 1.3067 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.5989 - loss: 1.4143 - val_accuracy: 0.6301 - val_loss: 1.3029 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6026 - loss: 1.4083 - val_accuracy: 0.6375 - val_loss: 1.3060 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001B[1m1228/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6060 - loss: 1.4075\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6059 - loss: 1.4077 - val_accuracy: 0.6294 - val_loss: 1.3383 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6200 - loss: 1.3263 - val_accuracy: 0.6573 - val_loss: 1.1742 - learning_rate: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6367 - loss: 1.2414 - val_accuracy: 0.6569 - val_loss: 1.1605 - learning_rate: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6388 - loss: 1.2213 - val_accuracy: 0.6531 - val_loss: 1.1748 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6432 - loss: 1.2211 - val_accuracy: 0.6508 - val_loss: 1.1660 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6354 - loss: 1.2311 - val_accuracy: 0.6588 - val_loss: 1.1641 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6430 - loss: 1.2187 - val_accuracy: 0.6635 - val_loss: 1.1478 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6462 - loss: 1.2114 - val_accuracy: 0.6610 - val_loss: 1.1562 - learning_rate: 5.0000e-04\n",
      "Epoch 38/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6434 - loss: 1.2109 - val_accuracy: 0.6568 - val_loss: 1.1601 - learning_rate: 5.0000e-04\n",
      "Epoch 39/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6461 - loss: 1.2048 - val_accuracy: 0.6595 - val_loss: 1.1490 - learning_rate: 5.0000e-04\n",
      "Epoch 40/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6429 - loss: 1.2129 - val_accuracy: 0.6590 - val_loss: 1.1612 - learning_rate: 5.0000e-04\n",
      "Epoch 41/100\n",
      "\u001B[1m1218/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6445 - loss: 1.2102\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6444 - loss: 1.2105 - val_accuracy: 0.6537 - val_loss: 1.1590 - learning_rate: 5.0000e-04\n",
      "Epoch 42/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6635 - loss: 1.1505 - val_accuracy: 0.6699 - val_loss: 1.0965 - learning_rate: 2.5000e-04\n",
      "Epoch 43/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6758 - loss: 1.0989 - val_accuracy: 0.6781 - val_loss: 1.0743 - learning_rate: 2.5000e-04\n",
      "Epoch 44/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6767 - loss: 1.0941 - val_accuracy: 0.6757 - val_loss: 1.0771 - learning_rate: 2.5000e-04\n",
      "Epoch 45/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6749 - loss: 1.0861 - val_accuracy: 0.6765 - val_loss: 1.0759 - learning_rate: 2.5000e-04\n",
      "Epoch 46/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6808 - loss: 1.0695 - val_accuracy: 0.6797 - val_loss: 1.0658 - learning_rate: 2.5000e-04\n",
      "Epoch 47/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6860 - loss: 1.0582 - val_accuracy: 0.6758 - val_loss: 1.0714 - learning_rate: 2.5000e-04\n",
      "Epoch 48/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6843 - loss: 1.0580 - val_accuracy: 0.6788 - val_loss: 1.0721 - learning_rate: 2.5000e-04\n",
      "Epoch 49/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6821 - loss: 1.0649 - val_accuracy: 0.6784 - val_loss: 1.0698 - learning_rate: 2.5000e-04\n",
      "Epoch 50/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6797 - loss: 1.0693 - val_accuracy: 0.6787 - val_loss: 1.0716 - learning_rate: 2.5000e-04\n",
      "Epoch 51/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6842 - loss: 1.0594 - val_accuracy: 0.6814 - val_loss: 1.0656 - learning_rate: 2.5000e-04\n",
      "Epoch 52/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6810 - loss: 1.0553 - val_accuracy: 0.6838 - val_loss: 1.0700 - learning_rate: 2.5000e-04\n",
      "Epoch 53/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6844 - loss: 1.0527 - val_accuracy: 0.6762 - val_loss: 1.0734 - learning_rate: 2.5000e-04\n",
      "Epoch 54/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6878 - loss: 1.0536 - val_accuracy: 0.6816 - val_loss: 1.0625 - learning_rate: 2.5000e-04\n",
      "Epoch 55/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6877 - loss: 1.0525 - val_accuracy: 0.6794 - val_loss: 1.0753 - learning_rate: 2.5000e-04\n",
      "Epoch 56/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6828 - loss: 1.0590 - val_accuracy: 0.6786 - val_loss: 1.0827 - learning_rate: 2.5000e-04\n",
      "Epoch 57/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6831 - loss: 1.0515 - val_accuracy: 0.6776 - val_loss: 1.0754 - learning_rate: 2.5000e-04\n",
      "Epoch 58/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6885 - loss: 1.0436 - val_accuracy: 0.6770 - val_loss: 1.0758 - learning_rate: 2.5000e-04\n",
      "Epoch 59/100\n",
      "\u001B[1m1238/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.6851 - loss: 1.0510\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6850 - loss: 1.0512 - val_accuracy: 0.6811 - val_loss: 1.0728 - learning_rate: 2.5000e-04\n",
      "Epoch 60/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.6990 - loss: 1.0110 - val_accuracy: 0.6863 - val_loss: 1.0427 - learning_rate: 1.2500e-04\n",
      "Epoch 61/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7069 - loss: 0.9790 - val_accuracy: 0.6874 - val_loss: 1.0427 - learning_rate: 1.2500e-04\n",
      "Epoch 62/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7114 - loss: 0.9691 - val_accuracy: 0.6885 - val_loss: 1.0298 - learning_rate: 1.2500e-04\n",
      "Epoch 63/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7099 - loss: 0.9673 - val_accuracy: 0.6847 - val_loss: 1.0432 - learning_rate: 1.2500e-04\n",
      "Epoch 64/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7162 - loss: 0.9554 - val_accuracy: 0.6851 - val_loss: 1.0374 - learning_rate: 1.2500e-04\n",
      "Epoch 65/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7133 - loss: 0.9530 - val_accuracy: 0.6901 - val_loss: 1.0360 - learning_rate: 1.2500e-04\n",
      "Epoch 66/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7167 - loss: 0.9439 - val_accuracy: 0.6891 - val_loss: 1.0345 - learning_rate: 1.2500e-04\n",
      "Epoch 67/100\n",
      "\u001B[1m1235/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7188 - loss: 0.9463\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7188 - loss: 0.9465 - val_accuracy: 0.6881 - val_loss: 1.0353 - learning_rate: 1.2500e-04\n",
      "Epoch 68/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7241 - loss: 0.9165 - val_accuracy: 0.6914 - val_loss: 1.0229 - learning_rate: 6.2500e-05\n",
      "Epoch 69/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7391 - loss: 0.8883 - val_accuracy: 0.6924 - val_loss: 1.0285 - learning_rate: 6.2500e-05\n",
      "Epoch 70/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7391 - loss: 0.8901 - val_accuracy: 0.6896 - val_loss: 1.0299 - learning_rate: 6.2500e-05\n",
      "Epoch 71/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7365 - loss: 0.8884 - val_accuracy: 0.6919 - val_loss: 1.0267 - learning_rate: 6.2500e-05\n",
      "Epoch 72/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7384 - loss: 0.8825 - val_accuracy: 0.6877 - val_loss: 1.0301 - learning_rate: 6.2500e-05\n",
      "Epoch 73/100\n",
      "\u001B[1m1241/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7400 - loss: 0.8781\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7400 - loss: 0.8782 - val_accuracy: 0.6904 - val_loss: 1.0262 - learning_rate: 6.2500e-05\n",
      "Epoch 74/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7468 - loss: 0.8620 - val_accuracy: 0.6909 - val_loss: 1.0251 - learning_rate: 3.1250e-05\n",
      "Epoch 75/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7430 - loss: 0.8717 - val_accuracy: 0.6917 - val_loss: 1.0269 - learning_rate: 3.1250e-05\n",
      "Epoch 76/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7459 - loss: 0.8510 - val_accuracy: 0.6914 - val_loss: 1.0256 - learning_rate: 3.1250e-05\n",
      "Epoch 77/100\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7486 - loss: 0.8492 - val_accuracy: 0.6917 - val_loss: 1.0271 - learning_rate: 3.1250e-05\n",
      "Epoch 78/100\n",
      "\u001B[1m1243/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.7461 - loss: 0.8502\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001B[1m1250/1250\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.7461 - loss: 0.8502 - val_accuracy: 0.6928 - val_loss: 1.0275 - learning_rate: 3.1250e-05\n",
      "Epoch 78: early stopping\n",
      "Restoring model weights from the end of the best epoch: 68.\n"
     ]
    }
   ],
   "execution_count": 230
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Evaluation",
   "id": "54e9bc9c17ff28e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T21:16:55.366158Z",
     "start_time": "2025-04-09T21:16:55.290253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "4218ca4535c7c62e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T21:17:02.431522Z",
     "start_time": "2025-04-09T21:17:02.130598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_scores = FCN_TOP.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test loss: {test_scores[0]:.2f}\")\n",
    "print(f\"Test accuracy: {test_scores[1]:.2f}\")"
   ],
   "id": "aab0af67c6b2e25e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.04\n",
      "Test accuracy: 0.68\n"
     ]
    }
   ],
   "execution_count": 232
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Summary\n",
    "\n",
    "In this notebook, I used the CIFAR-10 dataset to build a classifier by leveraging the VGG16 convolutional base for feature extraction. I experimented with several model architectures, but after multiple trials and only marginal progress, I decided to stop. To prevent overfitting and optimize training, I applied heavy regularization techniques such as EarlyStopping, ReduceLROnPlateau, L2 regularization, and Dropout.\n",
    "\n",
    "The classifier achieved a test accuracy of nearly 70%, which is reasonable but still below the 80% test accuracy we reached with a custom model built from scratch in the Neuroverkkoprojekti course. A potential reason for the relatively lower performance could be the mismatch in image sizes, as CIFAR-10 images are 32x32 pixels while VGG16 was originally designed for 224x224 input images."
   ],
   "id": "59f0baa1901241c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
